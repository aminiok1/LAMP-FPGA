{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAMP FPGA\n",
    "This notebook executes the LAMP model inference on Ultra96-V2 board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "from MPTimeSeriesGenerator import MPTimeseriesGenerator\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from pynq import Clocks\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock Frequency\n",
    "We set the PL clock frequency to 100MHz and PS clock frequency to 1.2GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clocks.cpu_mhz = 1200.0\n",
    "Clocks.fclk0_mhz = 100.0\n",
    "Clocks.fclk1_mhz = 100.0\n",
    "Clocks.fclk2_mhz = 100.0\n",
    "Clocks.fclk3_mhz = 100.0\n",
    "\n",
    "print(f'CPU:   {Clocks.cpu_mhz:.6f}MHz')\n",
    "print(f'FCLK0: {Clocks.fclk0_mhz:.6f}MHz')\n",
    "print(f'FCLK1: {Clocks.fclk1_mhz:.6f}MHz')\n",
    "print(f'FCLK2: {Clocks.fclk2_mhz:.6f}MHz')\n",
    "print(f'FCLK3: {Clocks.fclk3_mhz:.6f}MHz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the DPU overlay and the compiled LAMP model, create dpu kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = DpuOverlay(\"dpu.bit\")\n",
    "overlay.load_model(\"dpu_lamp_0.elf\")\n",
    "\n",
    "n2cube.dpuOpen()\n",
    "kernel = n2cube.dpuLoadKernel(\"lamp_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input data\n",
    "Prepare the time series input data using MPTimerSeriesGenerator class, this class takes in a sequence of data-points gathered at equal intervals with other parameters such as window size, stride, sample rate, etc., and generates batches of temporal data used as model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_profile_window = 256\n",
    "sample_rate = 20\n",
    "lookbehind_seconds = 0\n",
    "lookahead_seconds = 0\n",
    "subsequence_stride = 256\n",
    "lookbehind = sample_rate * lookbehind_seconds\n",
    "num_outputs = 256\n",
    "lookahead = sample_rate * lookahead_seconds\n",
    "forward_sequences = lookahead + num_outputs\n",
    "subsequences_per_input = lookbehind + num_outputs + lookahead\n",
    "channel_stride = 8\n",
    "n_input_series = 1\n",
    "subsequences_per_input = subsequences_per_input // channel_stride\n",
    "high_weight = 1\n",
    "low_thresh = -1\n",
    "high_thresh = 1\n",
    "batch_size = 128\n",
    "\n",
    "all_data = sio.loadmat('insect_no_classification.mat')\n",
    "\n",
    "mp_val = np.array(all_data['mp_val'])\n",
    "ts_val = np.array(all_data['ts_val'])\n",
    "\n",
    "valid_gen = MPTimeseriesGenerator(ts_val, mp_val, num_input_timeseries=1, internal_stride=8, num_outputs=256,lookahead=forward_sequences, lookbehind=lookbehind, important_upper_threshold=high_thresh, important_lower_threshold=low_thresh, important_weight=high_weight, length=256, mp_window=256, stride=num_outputs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a batch normalization layer before the activation layer reduces the compiled model accuracy, since the tool can not merge these layers; hence, this layer has been removed from the compiled model and the normalized data is computed in the PS and then fed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch normalization\n",
    "epsilon=1e-3\n",
    "\n",
    "N, C, H, W = data.shape\n",
    "# mini-batch mean\n",
    "mean = np.mean(data, axis=(0, 2, 3))\n",
    "# mini-batch variance\n",
    "variance = np.mean((data - mean.reshape((1, C, 1, 1))) ** 2, axis=(0, 2, 3))\n",
    "# normalize\n",
    "X_hat = (data - mean.reshape((1, C, 1, 1))) * 1.0 / np.sqrt(variance.reshape((1, C, 1, 1)) + epsilon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the application\n",
    "In order to increase the DPU kernel utilization and achieve a more efficient scheduling, we use a multithreading model. Each thread runs the model for one batch and moves to the next batch. The model is broken into four kernels, first we run the first kernel on FPGA, store the results, and feed them into the next kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dpu_task(index):\n",
    "  \n",
    "    task = n2cube.dpuCreateTask(0)\n",
    "    \n",
    "    result_index = index\n",
    "    \n",
    "    scale_in = n2cube.dpuGetInputTensorScale(task, \"conv2d_4_Conv2D\", 0)\n",
    "    scale_out = n2cube.dpuGetOutputTensorScale(task, \"conv2d_12_Conv2D\", 0)\n",
    "    \n",
    "    while index < len(valid_gen):\n",
    "        \n",
    "        vg = valid_gen[index]\n",
    "        \n",
    "        x_test, y_test = vg\n",
    "        x_test = np.float32(x_test)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            data = x_test[i][np.newaxis,...]\n",
    "            feed_data = data / scale_in\n",
    "\n",
    "            input_len = n2cube.dpuGetInputTensorSize(task, \"conv2d_4_Conv2D\")\n",
    "            n2cube.dpuSetInputTensorInHWCFP32(task, \"conv2d_4_Conv2D\", feed_data, input_len)\n",
    "            n2cube.dpuSetInputTensorInHWCFP32(task, \"conv2d_1_Conv2D\", feed_data, input_len)\n",
    "\n",
    "            n2cube.dpuRunTask(task)\n",
    "\n",
    "            conv_size = n2cube.dpuGetOutputTensorSize(task, \"conv2d_12_Conv2D\")\n",
    "            conv_out = n2cube.dpuGetOutputTensorInHWCFP32(task, \"conv2d_12_Conv2D\", conv_size)\n",
    "            \n",
    "            conv_out = np.reshape(conv_out1, (1, 256, 1, 192))\n",
    "            \n",
    "            results[result_index].append(conv_out)\n",
    "            index += thread_num\n",
    "\n",
    "    n2cube.dpuDestroyTask(task)\n",
    "\n",
    "thread_num = 8\n",
    "thread_all = []\n",
    "results = [None] * thread_num\n",
    "\n",
    "for i in range(thread_num):\n",
    "   \n",
    "    t1 = threading.Thread(target=run_dpu_task, args=(i))\n",
    "    thread_all.append(t1)\n",
    "    \n",
    "for t in thread_all:\n",
    "    t.start()\n",
    "for t in thread_all:\n",
    "    t.join()\n",
    "    \n",
    "n2cube.dpuDestroyKernel(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second kernel which is global average pool is implemented in the host CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_avg = [None] * thread_num\n",
    "\n",
    "for i in range(thread_num):\n",
    "    for r in results[i]:\n",
    "        out_scaled = r / scale_out\n",
    "\n",
    "        global_avg = np.apply_over_axes(np.mean, out_scaled, [1, 2])\n",
    "        results_avg[i].append(globa_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third kernel which is the dense layer is implemented on the FPGA, similar to the first layer we use a multithreading model to implement this kernel and gather the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"dpu_dense_2.elf\")\n",
    "\n",
    "n2cube.dpuOpen()\n",
    "kernel = n2cube.dpuLoadKernel(\"dense_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dpu_task_dense(index):\n",
    "    \n",
    "    task = n2cube.dpuCreateTask(kernel, 0)\n",
    "    \n",
    "    scale_in = n2cube.dpuGetInputTensorScale(task, \"dense_1_MatMul\", 0)\n",
    "    scale_out = n2cube.dpuGetOutputTensorScale(task, \"dense_1_MatMul\", 0)\n",
    "    \n",
    "    for res in results_avg[index]: \n",
    "    \n",
    "        feed_input = res / scale_in\n",
    "    \n",
    "        input_len = n2cube.dpuGetInputTensorSize(task, \"dense_1_MatMul\")\n",
    "        n2cube.dpuSetInputTensorInHWCFP32(task, \"dense_1_MatMul\", feed_data, input_len)\n",
    "\n",
    "        n2cube.dpuRunTask(task)\n",
    "\n",
    "        dense_size = n2cube.dpuGetOutputTensorSize(task, \"dense_1_MatMul\")\n",
    "        dense_out = n2cube.dpuGetOutputTensorInHWCFP32(task, \"dense_1_MatMul\", dense_size)\n",
    "        \n",
    "        dense_out = np.reshape(conv_out1, (1, 1, 1, 256))\n",
    "        \n",
    "        result_dense[index].append(dense_out)\n",
    "\n",
    "    \n",
    "    n2cube.dpuDestroyTask(task)\n",
    "\n",
    "thread_all = []\n",
    "result_dense = [None] * thread_num\n",
    "\n",
    "for i in range(thread_num):\n",
    "    t1 = threading.Thread(target=run_dpu_task_dense, args=(i))    \n",
    "    threadAll.append(t1)\n",
    "    \n",
    "for t in thread_all:\n",
    "    t.start()\n",
    "for t in thread_all:\n",
    "    t.join()\n",
    "    \n",
    "n2cube.dpuDestroyKernel(kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the last layer (Sigmoid function) is implemented in host and the results are written in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('predict.txt','a+')\n",
    "\n",
    "for i in range(thread_num):\n",
    "    for r in result_dense[i]:\n",
    "        \n",
    "        out_scaled = r / scale_out\n",
    "        sigmoid_out = 1/(1 + np.exp(-out_scaled))\n",
    "        \n",
    "        np.savetxt(f, sigmoid_out)\n",
    "\n",
    "f.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.mean(np.abs((sigmoid_out - y) / sigmoid_out)) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
